# ==============================================================================
# PROJET TDAH TUNISIE - MICS6 2023
# Script 06 : ModÃ¨les de Machine Learning
# ==============================================================================
# Description: ModÃ¨les de prÃ©diction du risque TDAH avec Random Forest
# Auteur: Asma BELKAHLA
# Date: 2026-01-02
# ==============================================================================

# 1. CONFIGURATION ============================================================

rm(list = ls())
gc()

# Charger les bibliothÃ¨ques
library(tidyverse)
library(randomForest)  # Random Forest
library(caret)         # Pour la validation croisÃ©e et les mÃ©triques
library(pROC)          # Pour les courbes ROC
library(ggplot2)       # Visualisations

project_root <- getwd()

# Charger les donnÃ©es avec score
load(file.path(project_root, "data", "processed", "05_risk_score.RData"))

cat("\n")
cat("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n")
cat("â•‘              MODÃˆLES DE MACHINE LEARNING - RANDOM FOREST           â•‘\n")
cat("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n")

cat("ğŸ“Š Dataset:", nrow(dataset_score), "enfants\n\n")

# 2. PRÃ‰PARATION DES DONNÃ‰ES ==================================================

cat("ğŸ”§ PRÃ‰PARATION DES DONNÃ‰ES\n")
cat(strrep("=", 70), "\n\n")

# SÃ©lectionner les variables pertinentes (sans sexe car 97% manquant)
# Convertir risque_tdah_eleve en facteur pour la classification
dataset_ml <- dataset_score %>%
  select(
    # Variable cible
    risque_tdah_eleve,
    score_tdah,

    # PrÃ©dicteurs
    age_annees,
    milieu,
    richesse_cat,
    educ_mere_cat,
    age_mere_cat,
    ordre_cat
  ) %>%
  # Supprimer les valeurs manquantes
  drop_na() %>%
  # Convertir la variable cible en facteur
  mutate(
    risque_tdah_eleve = factor(
      risque_tdah_eleve,
      levels = c(0, 1),
      labels = c("Non", "Oui")
    )
  )

cat("âœ… DonnÃ©es prÃ©parÃ©es:\n")
cat("   - Observations aprÃ¨s nettoyage:", nrow(dataset_ml), "\n")
cat("   - Variables prÃ©dictives:", ncol(dataset_ml) - 2, "\n")
cat("   - Variable cible: risque_tdah_eleve (Oui/Non)\n\n")

# Afficher la distribution de la variable cible
cat("ğŸ“Š Distribution de la variable cible:\n")
table(dataset_ml$risque_tdah_eleve) %>% print()
cat("\nProportion:\n")
prop.table(table(dataset_ml$risque_tdah_eleve)) %>%
  round(3) %>%
  print()
cat("\n\n")

# 3. SPLIT TRAIN/TEST =========================================================

cat("âœ‚ï¸ SÃ‰PARATION DES DONNÃ‰ES\n")
cat(strrep("=", 70), "\n\n")

# Fixer la graine pour la reproductibilitÃ©
set.seed(123)

# CrÃ©er l'index de sÃ©paration (70% train, 30% test)
train_index <- createDataPartition(
  dataset_ml$risque_tdah_eleve,
  p = 0.7,
  list = FALSE
)

# CrÃ©er les ensembles d'entraÃ®nement et de test
train_data <- dataset_ml[train_index, ]
test_data <- dataset_ml[-train_index, ]

cat("âœ… DonnÃ©es sÃ©parÃ©es:\n")
cat("   - Ensemble d'entraÃ®nement:", nrow(train_data), "observations\n")
cat("   - Ensemble de test:", nrow(test_data), "observations\n\n")

# VÃ©rifier l'Ã©quilibre des classes dans les deux ensembles
cat("Distribution dans l'ensemble d'entraÃ®nement:\n")
table(train_data$risque_tdah_eleve) %>% prop.table() %>% round(3) %>% print()

cat("\nDistribution dans l'ensemble de test:\n")
table(test_data$risque_tdah_eleve) %>% prop.table() %>% round(3) %>% print()
cat("\n\n")

# 4. MODÃˆLE 1: RANDOM FOREST ==================================================

cat("ğŸŒ² MODÃˆLE 1: RANDOM FOREST\n")
cat(strrep("=", 70), "\n\n")

cat("â³ EntraÃ®nement du modÃ¨le Random Forest...\n")

# EntraÃ®ner le modÃ¨le Random Forest
# ntree = nombre d'arbres, mtry = nombre de variables Ã  chaque split
set.seed(123)
rf_model <- randomForest(
  risque_tdah_eleve ~ age_annees + milieu + richesse_cat +
    educ_mere_cat + age_mere_cat + ordre_cat,
  data = train_data,
  ntree = 500,           # Nombre d'arbres
  mtry = 3,              # Nombre de variables par split
  importance = TRUE,     # Calculer l'importance des variables
  proximity = FALSE
)

cat("âœ… ModÃ¨le entraÃ®nÃ©!\n\n")

# Afficher le rÃ©sumÃ© du modÃ¨le
print(rf_model)
cat("\n")

# 5. IMPORTANCE DES VARIABLES =================================================

cat("ğŸ“Š IMPORTANCE DES VARIABLES\n")
cat(strrep("=", 70), "\n\n")

# Extraire l'importance des variables
importance_rf <- importance(rf_model) %>%
  as.data.frame() %>%
  rownames_to_column("Variable") %>%
  arrange(desc(MeanDecreaseGini))

cat("Importance des variables (Mean Decrease Gini):\n\n")
print(importance_rf, row.names = FALSE)
cat("\n")

# Visualisation de l'importance
importance_plot <- ggplot(
  importance_rf,
  aes(x = reorder(Variable, MeanDecreaseGini), y = MeanDecreaseGini)
) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(
    title = "Importance des Variables - Random Forest",
    x = "Variable",
    y = "Importance (Mean Decrease Gini)"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

print(importance_plot)
cat("\n")

# 6. PRÃ‰DICTIONS SUR L'ENSEMBLE DE TEST =======================================

cat("ğŸ¯ PRÃ‰DICTIONS SUR L'ENSEMBLE DE TEST\n")
cat(strrep("=", 70), "\n\n")

# Faire des prÃ©dictions
predictions_rf <- predict(rf_model, newdata = test_data, type = "class")
predictions_prob_rf <- predict(rf_model, newdata = test_data, type = "prob")

# 7. Ã‰VALUATION DU MODÃˆLE =====================================================

cat("ğŸ“ˆ Ã‰VALUATION DE LA PERFORMANCE\n")
cat(strrep("=", 70), "\n\n")

# Matrice de confusion
confusion_rf <- confusionMatrix(predictions_rf, test_data$risque_tdah_eleve)

cat("Matrice de Confusion:\n\n")
print(confusion_rf$table)
cat("\n")

cat("MÃ©triques de Performance:\n")
cat(strrep("-", 70), "\n")
cat("  PrÃ©cision (Accuracy):   ", round(confusion_rf$overall["Accuracy"] * 100, 2), "%\n")
cat("  SensibilitÃ© (Recall):   ", round(confusion_rf$byClass["Sensitivity"] * 100, 2), "%\n")
cat("  SpÃ©cificitÃ©:            ", round(confusion_rf$byClass["Specificity"] * 100, 2), "%\n")
cat("  PrÃ©cision (Precision):  ", round(confusion_rf$byClass["Precision"] * 100, 2), "%\n")
cat("  F1-Score:               ", round(confusion_rf$byClass["F1"] * 100, 2), "%\n")
cat("  Kappa:                  ", round(confusion_rf$overall["Kappa"], 3), "\n\n")

# 8. COURBE ROC ===============================================================

cat("ğŸ“Š COURBE ROC (Receiver Operating Characteristic)\n")
cat(strrep("=", 70), "\n\n")

# Calculer la courbe ROC
roc_rf <- roc(
  test_data$risque_tdah_eleve,
  predictions_prob_rf[, "Oui"],
  levels = c("Non", "Oui")
)

cat("AUC (Area Under Curve):", round(auc(roc_rf), 3), "\n")

# InterprÃ©tation de l'AUC
auc_value <- auc(roc_rf)
interpretation <- case_when(
  auc_value >= 0.9 ~ "Excellent",
  auc_value >= 0.8 ~ "TrÃ¨s bon",
  auc_value >= 0.7 ~ "Bon",
  auc_value >= 0.6 ~ "Moyen",
  TRUE ~ "Faible"
)
cat("InterprÃ©tation: ", interpretation, "\n\n")

# Visualisation de la courbe ROC
roc_plot <- ggroc(roc_rf) +
  geom_abline(intercept = 1, slope = 1, linetype = "dashed", color = "red") +
  labs(
    title = "Courbe ROC - Random Forest",
    x = "1 - SpÃ©cificitÃ© (Faux Positifs)",
    y = "SensibilitÃ© (Vrais Positifs)",
    subtitle = paste("AUC =", round(auc_roc), 3))
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

print(roc_plot)
cat("\n")

# 9. VALIDATION CROISÃ‰E =======================================================

cat("ğŸ”„ VALIDATION CROISÃ‰E (K-FOLD)\n")
cat(strrep("=", 70), "\n\n")

cat("â³ ExÃ©cution de la validation croisÃ©e 5-fold...\n")

# Configuration de la validation croisÃ©e
train_control <- trainControl(
  method = "cv",               # Validation croisÃ©e
  number = 5,                  # 5 folds
  classProbs = TRUE,           # Calculer les probabilitÃ©s
  summaryFunction = twoClassSummary,
  savePredictions = "final"
)

# EntraÃ®ner avec validation croisÃ©e
set.seed(123)
rf_cv <- train(
  risque_tdah_eleve ~ age_annees + milieu + richesse_cat +
    educ_mere_cat + age_mere_cat + ordre_cat,
  data = train_data,
  method = "rf",
  trControl = train_control,
  metric = "ROC",
  ntree = 500
)

cat("âœ… Validation croisÃ©e terminÃ©e!\n\n")

cat("RÃ©sultats de la validation croisÃ©e:\n")
cat(strrep("-", 70), "\n")
print(rf_cv$results)
cat("\n")

# 10. PRÃ‰DICTIONS INDIVIDUELLES (EXEMPLES) ====================================

cat("ğŸ” EXEMPLES DE PRÃ‰DICTIONS INDIVIDUELLES\n")
cat(strrep("=", 70), "\n\n")

# SÃ©lectionner quelques exemples
exemples <- test_data %>%
  slice_sample(n = 5) %>%
  mutate(
    Prediction = predict(rf_model, newdata = ., type = "class"),
    Prob_Risque_Eleve = round(
      predict(rf_model, newdata = ., type = "prob")[, "Oui"] * 100, 1
    )
  ) %>%
  select(
    VÃ©ritÃ© = risque_tdah_eleve,
    Prediction,
    Prob_Risque_Eleve,
    milieu,
    richesse_cat,
    educ_mere_cat
  )

cat("Exemples de prÃ©dictions:\n\n")
print(exemples, n = Inf)
cat("\n")

# 11. ANALYSE DES ERREURS =====================================================

cat("âŒ ANALYSE DES ERREURS DE CLASSIFICATION\n")
cat(strrep("=", 70), "\n\n")

# Identifier les faux positifs et faux nÃ©gatifs
erreurs <- test_data %>%
  mutate(
    Prediction = predict(rf_model, newdata = test_data, type = "class"),
    Erreur = case_when(
      risque_tdah_eleve == "Oui" & Prediction == "Non" ~ "Faux NÃ©gatif",
      risque_tdah_eleve == "Non" & Prediction == "Oui" ~ "Faux Positif",
      TRUE ~ "Correct"
    )
  )

cat("Nombre d'erreurs par type:\n")
table(erreurs$Erreur) %>% print()
cat("\n")

# Analyser les caractÃ©ristiques des erreurs
if (sum(erreurs$Erreur != "Correct") > 0) {
  cat("CaractÃ©ristiques des cas mal classÃ©s:\n\n")

  erreurs_summary <- erreurs %>%
    filter(Erreur != "Correct") %>%
    group_by(Erreur, milieu, richesse_cat) %>%
    summarise(n = n(), .groups = "drop") %>%
    arrange(desc(n))

  print(erreurs_summary, n = 20)
}

cat("\n")

# 12. SAUVEGARDE DES RÃ‰SULTATS ================================================

cat("ğŸ’¾ SAUVEGARDE DES RÃ‰SULTATS\n")
cat(strrep("=", 70), "\n\n")

# Sauvegarder le modÃ¨le et les rÃ©sultats
save(
  rf_model,
  rf_cv,
  confusion_rf,
  roc_rf,
  importance_rf,
  train_data,
  test_data,
  predictions_rf,
  predictions_prob_rf,
  file = file.path(project_root, "data", "processed", "06_ml_models.RData")
)

# Sauvegarder les mÃ©triques dans un CSV
metrics_df <- tibble(
  Metric = c("Accuracy", "Sensitivity", "Specificity", "Precision", "F1", "AUC"),
  Value = c(
    confusion_rf$overall["Accuracy"],
    confusion_rf$byClass["Sensitivity"],
    confusion_rf$byClass["Specificity"],
    confusion_rf$byClass["Precision"],
    confusion_rf$byClass["F1"],
    auc(roc_rf)
  )
) %>%
  mutate(Value = round(Value, 4))

write_csv(
  metrics_df,
  file.path(project_root, "data", "processed", "ml_metrics.csv")
)

# Sauvegarder l'importance des variables
write_csv(
  importance_rf,
  file.path(project_root, "data", "processed", "variable_importance.csv")
)

cat("âœ… RÃ©sultats sauvegardÃ©s:\n")
cat("   - 06_ml_models.RData (modÃ¨les et rÃ©sultats)\n")
cat("   - ml_metrics.csv (mÃ©triques de performance)\n")
cat("   - variable_importance.csv (importance des variables)\n\n")

# 13. RÃ‰SUMÃ‰ FINAL ============================================================

cat("\n")
cat("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n")
cat("â•‘                       RÃ‰SUMÃ‰ DE L'ANALYSE ML                       â•‘\n")
cat("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n")

cat("ğŸ“Š MODÃˆLE: Random Forest\n")
cat(strrep("-", 70), "\n")
cat("  - Nombre d'arbres:           ", rf_model$ntree, "\n")
cat("  - Variables par split:       ", rf_model$mtry, "\n")
cat("  - Taille Ã©chantillon train:  ", nrow(train_data), "\n")
cat("  - Taille Ã©chantillon test:   ", nrow(test_data), "\n\n")

cat("ğŸ¯ PERFORMANCE SUR L'ENSEMBLE DE TEST\n")
cat(strrep("-", 70), "\n")
cat("  - PrÃ©cision (Accuracy):      ", round(confusion_rf$overall["Accuracy"] * 100, 2), "%\n")
cat("  - AUC:                       ", round(auc(roc_rf), 3), "\n")
cat("  - F1-Score:                  ", round(confusion_rf$byClass["F1"], 3), "\n\n")

cat("ğŸ” TOP 3 VARIABLES LES PLUS IMPORTANTES\n")
cat(strrep("-", 70), "\n")
top3 <- importance_rf %>% slice_head(n = 3)
for (i in 1:3) {
  cat("  ", i, ". ", top3$Variable[i], " (",
      round(top3$MeanDecreaseGini[i], 2), ")\n", sep = "")
}

cat("\n")
cat("âœ… ANALYSE DE MACHINE LEARNING TERMINÃ‰E!\n")
cat("ğŸ“ Les rÃ©sultats sont prÃªts pour Ãªtre intÃ©grÃ©s au rapport.\n\n")

cat("ğŸ“Œ INTERPRÃ‰TATION\n")
cat(strrep("-", 70), "\n")
cat("Le modÃ¨le Random Forest identifie les enfants Ã  haut risque de TDAH\n")
cat("avec une prÃ©cision de", round(confusion_rf$overall["Accuracy"] * 100, 1), "%.\n")
cat("Les facteurs les plus prÃ©dictifs sont:\n")
cat("  1. La situation socio-Ã©conomique (richesse)\n")
cat("  2. L'Ã©ducation maternelle\n")
cat("  3. Le milieu de rÃ©sidence (urbain/rural)\n\n")

cat("ğŸš€ PROCHAINES Ã‰TAPES\n")
cat(strrep("-", 70), "\n")
cat("  - IntÃ©grer les rÃ©sultats dans rapport_principal.qmd\n")
cat("  - CrÃ©er des visualisations pour la prÃ©sentation\n")
cat("  - Documenter les recommandations de santÃ© publique\n\n")

# ==============================================================================
# FIN DU SCRIPT
# ==============================================================================
